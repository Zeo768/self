{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"><center>Exercise II:<br> Convolutional and Recurrent Neural Networks\n",
    "</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short summary\n",
    "In this exercise you will: \n",
    "\n",
    "* Train CNNs for a binary classification problem\n",
    "* Visualize how CNN interprets the data\n",
    "* Train a CNN for a 3-class classification problem\n",
    "* Train RNN on a time series prediction problem\n",
    "* Visualize how RNN hidden node activities\n",
    "* Sample from a RNN character model\n",
    "* (Optional) Train a CNN to count corners in polygons. (This problem is defined in another notebook.)\n",
    "\n",
    "In this lab we will look at network architectures that are designed to handle specific kinds of data. Convolutional Neural Networks for image processing and Recurrent Neural Networks for time series processing\n",
    "\n",
    "**Deadline for submitting the report: January 7, 12:00 (2020)**\n",
    "\n",
    "## The data\n",
    "Digits \"5\" and \"6\" from the MNIST database used for a binary classification problem.\n",
    "\n",
    "A dataset consisting of circles, rectangles or triangles. \n",
    "\n",
    "A dataset consisting of pairs of times series. The input time series is a train of rectangle pulses, and the output is triangles, i.e. an up-ramp followed by a down-ramp. For more details see the cell *Ex4-1*. The task is to train a recurrent network that predicts the triangle time series from the pulse time series.\n",
    "\n",
    "The last exercise is using the Tensorflow source code (C++) represented as a long sequence of characters. See that cell for more details.\n",
    "\n",
    "## The exercises\n",
    "As for the previous lab all exercises are found below.\n",
    "\n",
    "## The different 'Cells'\n",
    "This notebook contains several cells with python code, together with the markdown cells (like this one) with only text. Each of the cells with python code has a \"header\" markdown cell with information about the code. The table below provides a short overview of the code cells. \n",
    "\n",
    "| #  |  CellName | CellType | Comment |\n",
    "| :--- | :-------- | :-------- | :------- |\n",
    "| 1 | Init | Needed | Sets up the environment|\n",
    "| 2 | Data | Needed | Loading images for the CNN exercise |\n",
    "| 3 | PlotImg | Information  | View some of the images |\n",
    "| 4 | Stats | Needed | Compute classification results |\n",
    "| 5 | Ex1 | Exercise | For question 1-2 |\n",
    "| 6 | Ex2 | Exercise | For question 3 |\n",
    "| 7 | Ex3 | Exercise | For question 4 |\n",
    "| 8 | Ex4-1 | Exercise | For question 5-8 |\n",
    "| 9 | Ex4-2 | Exercise | For question 5-8 |\n",
    "| 10 | Ex4-3 | Exercise | For question 5-8 |\n",
    "| 11 | Ex5-1 | Exercise | For question 9-10 |\n",
    "| 12 | Ex5-2 | Exercise | For question 9-10 |\n",
    "\n",
    "\n",
    "In order for you to start with the exercise you need to run all cells with the CellType \"Needed\". The very first time you start with this exercise we suggest that you enter each of the needed cells, read the cell instruction and run the cell. It is important that you do this in the correct order, starting from the top and work you way down the cells. Later when you have started to work with the notebook it may be easier to use the command \"Run All\" found in the \"Cell\" dropdown menu.\n",
    "\n",
    "## Writing the report\n",
    "First the report should be written within this notebook. We have prepared the last cell in this notebook for you where you should write the report. The report should contain 4 parts:\n",
    "\n",
    "* Name:\n",
    "* Introduction: A **few** sentences where you give a small introduction of what you have done in the lab.\n",
    "* Answers to questions: For each of the questions provide an answer. It can be short answers or a longer ones depending on the nature of the questions, but try to be effective in your writing.\n",
    "* Conclusion: Summarize your findings in a few sentences.\n",
    "\n",
    "It is important that you write the report in this last cell and **not** after each question! When you are ready upload your report to Live@Lund.\n",
    "\n",
    "## Last but not least\n",
    "Have fun again!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Init (#1)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Initializing the libraries\n",
    "In the cell below, we import all the libraries that are needed for this exercises. There is one configuration parameter that you can change in this cell\n",
    "\n",
    "* Inline or \"pop out\" plots.\n",
    "\n",
    "See comments in the cell for more information. Run the cell by entering into the cell and press \"CTRL Enter\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18164878704391457107\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# These two lines is just to avoid some warnings, coming from the fact that we are running\n",
    "# tensorflow 1.14 and not the latest version.\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Lambda, concatenate\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, RNN\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Nadam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# To have the plots inside the notebook \"inlin\" should be True. \n",
    "# If \"inlin\" = False, then plots will pop out of the notebook\n",
    "inlin = True # True/False\n",
    "if inlin:\n",
    "    %matplotlib inline\n",
    "else:\n",
    "    %matplotlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Data (#2)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Function for getting images for the CNN exercises\n",
    "\n",
    "This cell defines the functions that obtain the images needed for the CNN exercise. Note! Later when you actually call these function, if it can't find the files, make sure the \"crt-trn/\" and \"crt-tst/\" folders are available in the same directory as this notebook file.\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImagesCRT(N=500):\n",
    "    import imageio\n",
    "    def load_pics(folder,N):\n",
    "        imgs = []\n",
    "        for i in range(N):\n",
    "            img = imageio.imread(folder+\"img_{:05}.png\".format(i+1))\n",
    "            ch = img[:,:,0]\n",
    "            imgs.append(ch)\n",
    "        return np.array(imgs)\n",
    "\n",
    "    def load_labels(fn):\n",
    "        return np.loadtxt(fn, usecols=(0,1,2))\n",
    "\n",
    "    base = \"./\"\n",
    "    trainpic = load_pics(base + \"crt-trn/\", N)\n",
    "    testpic = load_pics(base + \"crt-tst/\", 1000)\n",
    "    ntrain, width, height = trainpic.shape\n",
    "\n",
    "    xtrain = (trainpic/np.float32(255)).reshape(N, width, height, 1)\n",
    "    xtest = (testpic/np.float32(255)).reshape(1000, width, height, 1)\n",
    "\n",
    "    ytrain = load_labels(base+\"crt-trn_trg.csv\")\n",
    "    ytrain = ytrain[:N]\n",
    "    ytest = load_labels(base+\"crt-tst_trg.csv\")\n",
    "\n",
    "    #xtrain = xtrain[:250]\n",
    "    \n",
    "    return xtrain, ytrain, xtest, ytest, width, height\n",
    "\n",
    "\n",
    "def loadMNIST56():\n",
    "    xtrain, ytrain, xtest, ytest = np.load(\"mnist56.npy\", allow_pickle=True)\n",
    "    width, height = xtrain.shape[1:3]\n",
    "    return xtrain, ytrain, xtest, ytest, width, height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: PlotImg (#3)\n",
    "### CellType: Information\n",
    "### Cell instruction: Show some of the images\n",
    "\n",
    "Here we look at the first ten pictures in the training set, and their respective targets. You can select the dataset to look at by uncomment the correct line.\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "xtrain, ytrain, xtest, ytest, width, height = loadImagesCRT(10)\n",
    "#xtrain, ytrain, xtest, ytest, width, height = loadMNIST56()\n",
    "\n",
    "plt.figure(1, figsize=(15,10))\n",
    "plt.imshow(xtrain[:10,:,:].swapaxes(0,1).reshape(width,10*height),cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Targets:\")\n",
    "print(ytrain[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Stats (#4)\n",
    "### CellType: Needed\n",
    "### Cell instruction: Get binary and 3-class classification results\n",
    "\n",
    "This cell just defines functions that we can call to compute som performance measures for binary and 3-class classification problems.\n",
    "\n",
    "Run the cell by entering into the cell and press \"CTRL Enter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_pred_stats(ytrue, ypred, threshold=0.5):\n",
    "    one_correct = np.sum((ytrue==1)*(ypred > threshold))\n",
    "    zero_correct = np.sum((ytrue==0)*(ypred <= threshold))\n",
    "    sensitivity = one_correct / np.sum(ytrue==1)\n",
    "    specificity = zero_correct / np.sum(ytrue==0)\n",
    "    accuracy = (one_correct + zero_correct) / len(ytrue)\n",
    "    return sensitivity, specificity, accuracy\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.ylim([-0.5, cm.shape[0]-0.5])\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "def multi_stat_3(model = None, x_test = None, y_test = None, lbl = None):\n",
    "    y_pred = model.predict(x_test, verbose=0 )\n",
    "    print(lbl,' log_loss:  ', log_loss(y_test, y_pred, eps=1e-15))\n",
    "\n",
    "    y_true = y_test.argmax(axis=1)\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    print(lbl, ' accuracy:  ',(y_pred==y_true).mean(), '\\n')\n",
    "\n",
    "    target_names = ['class {}'.format(i+1) for i in range(3)]\n",
    "\n",
    "    confuTst = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm           = confuTst, \n",
    "                          normalize    = False,\n",
    "                          target_names = target_names,\n",
    "                          title        = \"Confusion Matrix: \" + lbl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex1 (#5)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 1-2\n",
    "\n",
    "## CNN for image classification\n",
    "\n",
    "In this first exercise you are going to train a CNN that can separate between numbers \"5\" and \"6\" from the mnist dataset (mnist56 dataset). We are going to use 2000 training images and 1850 test images. To start with we have a proposed CNN that can solve this problem. It consists of the following:\n",
    "* First convolutional layer consisting of 4 kernels of size 3x3, with ReLU activation\n",
    "* Maxpooling of size 2x2\n",
    "* Second convolutional layer of 4 kernels of size 3x3, with ReLU activation\n",
    "* Maxpooling of size 2x2\n",
    "* Special layer *Flatten()*, just transforms the all of the max pooled filter outputs to a linear vector of outputs\n",
    "* *Dense* layer, meaning a fully connected MLP like layer with 10 nodes, again ReLU activation\n",
    "* Final output layer consisting of one single output node with sigmoid activation function because we have a binary classification problem.\n",
    "\n",
    "The default is to use *stride* = 1 and no *padding*. \n",
    "\n",
    "#### Question 1\n",
    "Make sure you understand the definition of the CNN model in the cell below and train it. **What is your test set performance in terms of the accuracy?**\n",
    "\n",
    "#### Question 2\n",
    "This image classification problem should be relatively easy since a \"5\" has some distict differences from a \"6\". Experiment with the architecture of the CNN model and try to make it smaller, but with the same almost perfect test accuracy. **How many parameters do you have in your trimmed model and state your architecture?**\n",
    "\n",
    "**Hint:** There is of course very many ways you can make a smaller architecture. You do not need to test all of them!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 4)         148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,209\n",
      "Trainable params: 1,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 1.0 1.0 1.0\n",
      "test set:  0.9937369519832986 0.9865470852017937 0.9902702702702703\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset, MNIST-56\n",
    "xtrain, ytrain, xtest, ytest, width, height = loadMNIST56()\n",
    "\n",
    "# The size of the images\n",
    "input_shape = (width, height, 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First conv layer\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second conv layer\n",
    "model.add(Conv2D(4, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fully connected MLP layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# We use cross entropy error and the adam optimizer\n",
    "adam = Adam(lr=0.005)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Now train the model\n",
    "estimator = model.fit(xtrain, ytrain, \n",
    "                      validation_data=(xtest, ytest),\n",
    "                      epochs=30, \n",
    "                      batch_size=50,\n",
    "                      verbose=0)\n",
    "\n",
    "# Plot the training error\n",
    "plt.plot(estimator.history['loss'])\n",
    "plt.plot(estimator.history['val_loss'])\n",
    "plt.title('Model training')\n",
    "plt.ylabel('training error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=0)\n",
    "plt.show()\n",
    "\n",
    "# Get the training predictions and results for those\n",
    "predtrain = model.predict(xtrain)[:,0]\n",
    "sensitivity, specificity, accuracy = binary_pred_stats(ytrain, predtrain)\n",
    "print(\"train set:\", sensitivity, specificity, accuracy)\n",
    "\n",
    "# Get the test predictions and the results for those\n",
    "predtest = model.predict(xtest)[:,0]\n",
    "sensitivity, specificity, accuracy = binary_pred_stats(ytest, predtest)\n",
    "print(\"test set: \", sensitivity, specificity, accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex2 (#6)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 3\n",
    "\n",
    "You are now going to take a look into the CNN model. There are many attempts to visualize how the CNN model is making classifications. We will here just look at the different filter outputs given an input image. So the code in the cell below will do the following:\n",
    "* Select an image\n",
    "* Make a forward pass through the CNN remembering all intermediate values.\n",
    "* Plot all of the filters for each of the layers.\n",
    "* One can select to plot before or after the MaxPooling.\n",
    "\n",
    "This cell relies on the fact that you have run the cell above (Ex1) so that test data has been defined and you have a trained model.\n",
    "\n",
    "#### Question 3\n",
    "Train a CNN for the \"5\" vs \"6\" provlem! As a suggestion use the following CNN\n",
    "\n",
    "*3x(3x3 kernel)-maxpool-3x(3x3 kernel)-maxpool-(Flatten)-Dense(5)-Dense(1)*\n",
    "\n",
    "Make sure that your trained model gives good test results (i.e. > 95% accuracy). Having such a model, you can run the cell below. There are two parameters in the cell, *post_pool* or *idx*. The post_pool variable can be set to *True* meaning that filters will be shown after MaxPooling. The image to show is selected by the *idx* variable. As an example, the following values represent,\n",
    "* idx=1 number \"6\"\n",
    "* idx=2 numner \"5\"\n",
    "* idx=3 another number \"6\"\n",
    "* idx=5 antoher number \"5\"\n",
    "\n",
    "**Can you find some property in the filters that makes sense when it comes to separating \"5\" from \"6\"?**\n",
    "\n",
    "Hint! If you repeat the training you may get new filters!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if True then Maxpooling will be applied before showing the filter\n",
    "post_pool = False\n",
    "\n",
    "# The image index to show\n",
    "idx = 5\n",
    "\n",
    "kind = MaxPooling2D if post_pool else Conv2D\n",
    "outs = [l.output for l in model.layers if isinstance(l, kind)]\n",
    "#outs = [model.layers[0].input] + [l.output for l in model.layers if isinstance(l, kind)]\n",
    "intermediate = K.function([model.layers[0].input, K.learning_phase()], outs)\n",
    "print(ytest[idx])\n",
    "states = [xtest[idx:idx+1]] + intermediate([xtest[idx:idx+1], 0])\n",
    "#states = intermediate([xtest[idx:idx+1], 0])\n",
    "plt.figure(figsize=(18,12))                    \n",
    "for k,s in enumerate(states):\n",
    "    plt.figure(figsize=(18,12))\n",
    "    plt.subplot(len(outs)+1,1,k+1)\n",
    "    #plt.subplot(len(outs),1,k+1)\n",
    "    pics = s[0]\n",
    "    pics = np.rollaxis(pics,2,0)\n",
    "    rows = 2 if pics.shape[0] > 8 else 1\n",
    "    cols = pics.shape[0]//rows\n",
    "    imgshape = pics.shape[1:]\n",
    "    pics = pics.reshape((rows,cols)+imgshape)\n",
    "    pics = pics.swapaxes(1,2)\n",
    "    pics = pics.reshape((pics.shape[0]*pics.shape[1], pics.shape[2]*pics.shape[3]))\n",
    "    extent = (0,cols*imgshape[0], 0,rows*imgshape[1])\n",
    "    plt.imshow(pics,cmap='gray',extent=extent)\n",
    "    for r in range(1,rows):\n",
    "        plt.plot([0,cols*imgshape[0]], [r*imgshape[1], r*imgshape[1]], color='r', linestyle='-', linewidth=1)\n",
    "    for c in range(1,cols):\n",
    "        plt.plot([c*imgshape[0], c*imgshape[0]], [0,rows*imgshape[1]], color='r', linestyle='-', linewidth=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex3 (#7)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 4\n",
    "\n",
    "## CNN for image classification\n",
    "\n",
    "In this exercise you are going to train a CNN that can separate between circles, squares and triangles, the CRT dataset. We are going to use 500 training images and 1000 test images. Code are provided for loading the data, training the model and presenting the result. Your task is to define the actual CNN model and see how it performs.\n",
    "\n",
    "#### Question 4\n",
    "Define your own CNN model for classifying the images in the CRT data into three classes. **Provide the details of your CNN model and present the test result.**\n",
    "\n",
    "**Hint:** Remember the difference between a binary classifier and a multi-class classifier!\n",
    "\n",
    "#### Bonus question \n",
    "(You do not need to answer this one.) You can run the code in cell #6 also for this model. It will show you the different filter outputs. Again try to understand the features the different filter learn to separate between circles, triangles and rectangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CRT dataset\n",
    "xtrain, ytrain, xtest, ytest, width, height = loadImagesCRT()\n",
    "print('Training data input shape: ', xtrain.shape)\n",
    "print('Training data output shape: ', ytrain.shape)\n",
    "print('Test data input shape: ', xtest.shape)\n",
    "print('Test data output shape: ', ytest.shape)\n",
    "\n",
    "# The size of the images\n",
    "input_shape = (width, height, 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "\"\"\" \n",
    "Put your CNN model here\n",
    "\"\"\"\n",
    "\n",
    "# We use cross entropy error and the adam optimizer\n",
    "adam = Adam(lr=0.005)\n",
    "model.compile(loss='YOUR LOSS FUNCTION', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Now train the model\n",
    "estimator = model.fit(xtrain, ytrain, \n",
    "                      validation_data=(xtest, ytest),\n",
    "                      epochs=30, \n",
    "                      batch_size=50,\n",
    "                      verbose=0)\n",
    "\n",
    "# Plot the training error\n",
    "plt.plot(estimator.history['loss'])\n",
    "plt.plot(estimator.history['val_loss'])\n",
    "plt.title('Model training')\n",
    "plt.ylabel('training error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=0)\n",
    "plt.show()\n",
    "\n",
    "multi_stat_3(model,xtest,ytest,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex4-1 (#8)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 5-8\n",
    "\n",
    "## RNN as a pulse converter\n",
    "We will now look at recurrent networks! This exercise is using divided into three cells below. We start by loading and visualizing the data. **Note!** The actual questions for this part can be found in cell *Ex4-3* below.\n",
    "\n",
    "### Loading and visualizing the data\n",
    "The cell below loads the training data and the test data from existing binary python files and plots one set of training/test data, both the input sequence and the target sequence. Run the cell by entering into the cell and press \"CTRL Enter\".\n",
    "\n",
    "How is data generated? The input sequence consists of square pulses with varying length and height. The waiting time between the pulses is also varying within some predefined ranges. The lower limit is 2 times the length of the previous pulse. The target triangle pulse sequence is built from the input sequence as follows:\n",
    "* the triangle pulse start when the input square pulse have ended.\n",
    "* the width of the triangle (at the base) is twice the width of the square pulse.\n",
    "* the height of the triangle is the same as the height of the square pulse.\n",
    "\n",
    "The task is now to learn this mapping using a recurrent neural network. There are 100 input/target sequences in the training data and 100 in the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load data from files\n",
    "x,y = np.load(\"rnn_traindata.npy\")\n",
    "xtest,ytest = np.load(\"rnn_testdata.npy\")\n",
    "\n",
    "# If this is set to True, then we have the reverse problem. Input triangle pulse, target square puls.\n",
    "if False:\n",
    "    y,x = x[:,::-1],y[:,::-1]\n",
    "    ytest,xtest = xtest[:,::-1], ytest[:,::-1]\n",
    "\n",
    "ns,tlen = x.shape\n",
    "t = np.arange(tlen)\n",
    "\n",
    "# The training /validation case to look at\n",
    "i = 3\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(t,x[i,:])\n",
    "plt.legend(['Training, input sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(t,y[i,:])\n",
    "plt.legend(['Training, target sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(t,xtest[i,:])\n",
    "plt.legend(['Test, input sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(t,ytest[i,:])\n",
    "plt.legend(['Test, target sequence'], loc=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex4-2 (#9)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 5-8\n",
    "\n",
    "## RNN as a pulse converter\n",
    "### define the model and train\n",
    "Here we are going to setup the model and train it. There are three different models to choose from: \n",
    "*SimpleRNN: Simple feedback weights where the output from a node is feeding back to itself. For several hidden nodes there are feedback weights to all other nodes in the layer.\n",
    "* LSTM: The LSTM unit\n",
    "* GRU: The GRU unit\n",
    "\n",
    "The standard choice of activation function is *tanh*, but you can also test *relu*. When it comes to training this model we are goint to use a possible truncated BPTT approach. The support in Keras for doing this is somewhat limited so here it is implemented manually. In short we have 100 training sequences and we define a mini-batch size *mb* that selects *mb* of these sequences to train using the normal stochastic gradient descent idea. Then we have a variable *batchlen* that is the length of the sequence to use in truncated BPTT. The default values for these are *mb=10* and *batchlen=50*. If you want to train without the truncated BPTT approach put *batchlen=100*.\n",
    "\n",
    "During training we print the normalized training and test error. Normalized means here that the loss (=MSE) is divided by the variance of the target signal. So that a normalized error of 1 is not so good, but if we get below 0.1 (or so) it means that the error is much smaller than the signal itself.\n",
    "\n",
    "What you need to do in this cell is to define your model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ns,tlen = x.shape\n",
    "\n",
    "# Parameters defining the mini-batch size and \n",
    "# the sequence length for truncated BPTT\n",
    "mb = 10\n",
    "nmb = ns//mb\n",
    "batchlen = 50\n",
    "ntsteps = tlen//batchlen\n",
    "\n",
    "# The network type\n",
    "net = SimpleRNN\n",
    "#net = GRU\n",
    "#net = LSTM\n",
    "\n",
    "# Number of hidden nodes\n",
    "nh1 = 5\n",
    "\n",
    "# This is only if you would like to add an additional hidden layer. See below.\n",
    "nh2 = 5\n",
    "\n",
    "# The activation function\n",
    "activation = 'tanh'\n",
    "#activation = 'relu'\n",
    "\n",
    "# The number of epochs\n",
    "nE = 20\n",
    "\n",
    "#Start defining the model\n",
    "model = Sequential()\n",
    "model.add(net(nh1, \n",
    "              batch_input_shape=(mb,batchlen,1), \n",
    "              stateful=True, \n",
    "              return_sequences=True, \n",
    "              activation=activation))\n",
    "\n",
    "# Uncomment this line if you want to add an additional hidden layer\n",
    "#model.add(net(nh2, stateful=True, return_sequences=True, activation=activation))\n",
    "\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "adam = Adam(lr=0.003)\n",
    "model.compile(optimizer=adam,loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "# Now the training part\n",
    "trnTrgVar = np.var(y[:,:])        # Variance for train target signal\n",
    "testTrgVar = np.var(ytest[:,:])   # Variance for test target signal\n",
    "ndone = 0\n",
    "\n",
    "print('Epoch', 'Time/Epoch', ' Train-Err', '  Test-Err')\n",
    "for ne in range(nE):\n",
    "    t0 = time.time()\n",
    "    sumloss = 0\n",
    "    for batch in range(nmb):\n",
    "        i1,i2 = batch*mb,(batch+1)*mb\n",
    "        model.reset_states()\n",
    "        for tstep in range(ntsteps):\n",
    "            t1,t2 = tstep*batchlen,(tstep+1)*batchlen\n",
    "            loss = model.train_on_batch(x[i1:i2,t1:t2,None], y[i1:i2,t1:t2,None])\n",
    "            sumloss += loss\n",
    "    meanloss = sumloss/(nmb*ntsteps)\n",
    "\n",
    "    # Test error\n",
    "    sumlossvalid = 0\n",
    "    for batch in range(nmb):\n",
    "        i1,i2 = batch*mb,(batch+1)*mb\n",
    "        model.reset_states()\n",
    "        for tstep in range(ntsteps):\n",
    "            t1,t2 = tstep*batchlen,(tstep+1)*batchlen\n",
    "            loss = model.evaluate(xtest[i1:i2,t1:t2,None], ytest[i1:i2,t1:t2,None],batch_size=mb,verbose=0)\n",
    "            sumlossvalid += loss\n",
    "    meanlossvalid = sumlossvalid/(nmb*ntsteps)\n",
    "    t1 = time.time()\n",
    "    ndone += 1\n",
    "    print(ndone, \"    {:.2f}        {:.5f}     {:.5f}\".format(t1-t0, meanloss/trnTrgVar, meanlossvalid/testTrgVar))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex4-3 (#10)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 5-8\n",
    "\n",
    "## RNN as a pulse converter\n",
    "### Plot the result\n",
    "In this cell we just plot the result for one of the first 10 test sequences. You can select which of these ones by an index (see the code). Also, the last graph shows the hidden node activation for all of the hidden nodes. **Note:** For the GRU and simpleRNN models this all of the hidden activity there is, but for the LSTM there is also the memory signal. This one is not shown!\n",
    "\n",
    "### Questions\n",
    "We are now finally at the point of asking questions. Whenever you define a new model and train it, you need to run the  cell below in order to show the result for the newly trained model. \n",
    "\n",
    "**Hint!** For all of the questions below you are going to train different models. Keep an eye on how the training error is developing. If you see large fluctuations, you may to change the learning rate. The default value of 0.003 should be OK for most trainings. \n",
    "\n",
    "#### Question 5\n",
    "(Just to get started!) Define a simpleRNN model with 5 hidden nodes and train it for about 20 epochs. **What test error do you obtain?** \n",
    "\n",
    "Hint: The test error can be found during \"training\" as the error for the last epoch.\n",
    "Hint: You may have to train a couple of times to make sure that you did not end up in a \"bad\" local minima the first time.\n",
    "\n",
    "#### Question 6\n",
    "Test different models! Train three different models with the same number of hidden nodes (e.g. 4) and decide which of them that works best? **So, out of the three different models, *simpleRNN, GRU och LSTM*, which one worked best using the same number of hidden nodes?**\n",
    "\n",
    "Comment: Of course the different models uses different amount of weights, so one can argue that it is not a fair comparison!\n",
    "\n",
    "#### Question 7\n",
    "Interpretation! You are now going to interpret the hidden node outputs. Remember that the actual output for each time is just a linear combination of the hidden node outputs. As said before you can see the hidden nodes output in the last plot. Note that the weights in the dense layer can have different signs so that hidden nodes outputs can be linearly combined with both positve and negatives signs. Train a *GRU* model with 3 hidden nodes for about 20 epochs. **Try to explain what the different hidden nodes are actually detecting**.\n",
    "\n",
    "Comment: This is of course a question with no definite true answer. We just want you to interpret what the different nodes are doing.\n",
    "\n",
    "#### Question 8\n",
    "If you look at the top of cell *Ex4-1* you can, by changing False -> True, define the reverse problem. That is, input is the triangle pulse and target is the square pulse. This should be a more difficult problem! **Why?** **Present a RNN model that can \"solve\" this reverse problem (i.e. below 0.1 in test error).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xshow = xtest[:mb]\n",
    "yshow = ytest[:mb]\n",
    "yout = np.zeros((mb,tlen))\n",
    "hidden1 = np.zeros((mb,tlen,nh1))\n",
    "hidden2 = np.zeros((mb,tlen,nh2))\n",
    "\n",
    "rnn1 = model.layers[0]\n",
    "rnn2= model.layers[1]\n",
    "\n",
    "#dense = model.layers[-1]\n",
    "#sign = K.sign(dense.layer.kernel)[None,None,:,0]\n",
    "if len(model.layers) > 2 :\n",
    "    intermediate = K.function([rnn1.input], [rnn1.output, rnn2.output ])\n",
    "else :\n",
    "    intermediate = K.function([rnn1.input], [rnn1.output])\n",
    "\n",
    "for tstep in range(ntsteps):\n",
    "    t1,t2 = tstep*batchlen,(tstep+1)*batchlen\n",
    "    inp = xshow[:,t1:t2,None]\n",
    "    if len(model.layers) > 2 :\n",
    "        hi,hi2 = intermediate([inp])\n",
    "        hidden2[:,t1:t2:,:] = hi2\n",
    "    else :\n",
    "        hi, = intermediate([inp])\n",
    "    hidden1[:,t1:t2:,:] = hi\n",
    "    yi = model.predict(xshow[:,t1:t2,None])\n",
    "    yout[:,t1:t2] = yi[:,:,0]\n",
    "\n",
    "t = np.arange(tlen)\n",
    "\n",
    "# Selection of test sequnce. i=0 is rather easy, i=1 is a difficult one\n",
    "i = 1\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(t,xshow[i],'-',marker='.')\n",
    "plt.legend(['Training, input sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(t,yshow[i],'-',marker='.')\n",
    "plt.plot(t,yout[i],'-',marker='.')\n",
    "plt.legend(['Test, target sequnce', 'Test, predicted sequence'], loc=0)\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(t,hidden1[i],'-',marker='.')\n",
    "plt.title('Hidden 1 node outputs')\n",
    "\n",
    "if len(model.layers) > 2 :\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(t,hidden2[i],'-',marker='.')\n",
    "    plt.title('Hidden 2 node outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex5-1 (#11)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 9-10\n",
    "\n",
    "## RNN: Sampling from a character model\n",
    "As a final exercise we are going to look into an example where a recurrent network is used to predict a sequence of characters. The model is autoregressive, meaning that the previous values $\\ldots, x_{i-2}, x_{i-1}$ is used to predict $x_i$. In the model characters are represented as vectors with the same number of elements as the number of unique characters in the sequence. The input in each sequence step is a single character, represented using \"one-hot\" coding, that is exactly one vector element is one, representing that particular character. The output is on the other hand a probability vector over all characters, which can be used to sample a character from the predictive distribution. To sample long sequences of characters, we feed one sampled character back into the network, to predict the character after that and so on.\n",
    "\n",
    "The sequence of characters that we are going to train on is the source code of Tensorflow (C++). The size of the downloaded source code is approximately 14 Mb, which means about 14 million characters in the sequence. The number of unique characters is 103. Therefore the output layer consists of 103 nodes with a softmax activation function. The RNN model itself is rather large, it consists of two layers of 1024 LSTM nodes in each layer. In addition to that there are skip-layer connections from input to second hidden layer and skip connections from first hidden layer to the output layer. In total there are about 13.5 million weights in this model.\n",
    "\n",
    "This model take too long time to train as part of this lab. It takes days rather than minutes to train! Therefore pre-trained weights are handed out as part of the lab material. This is the file that you needed to download from an external URL!\n",
    "\n",
    "Given such a model we can now \"sample\" from it. Given some initial sequence of characters, as a seed, we can run the model for a number of sequence steps in order to find the sequence of predicted characters. But we can do more! Since the output is a vector of probabilities for new characters we can sample from it. As an example assume we only have 5 characters in our vocabulary and the prediction for a new character is:\n",
    "\n",
    "(0.1, 0.3, 0.5, 0.0, 0.1)\n",
    "\n",
    "So the character represented by the third position would be selected since it has the largest probability. But if we treat these number as probabilities we can say that half of the times we are going to select the third character, 30% of the time we select the character represented by the second position and so on. To even make things more random we can modify these probabilities such that they become more equal (high temperature) or that the largest probability becomes even larger (small temperature). This temperature parameter *temp* can be changed so that the sampling becomes completely random (very high *temp*) or completely deterministic (very low *temp*).\n",
    "\n",
    "The code cell below just defines the model and loads the pre-trained weights onto the model. Run the cell! It can take some seconds to do that!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of all chars appearing in tensorflow source code:\n",
    "chars = ['\\t', '\\n'] + [chr(x) for x in range(32,127)] + ['', '', '', '', '', '\\ufeff']\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# build the model: two layers of LSTM\n",
    "nh = 1024\n",
    "arch = LSTM\n",
    "inp = Input(batch_shape=(1, 1, len(chars)))\n",
    "h1layer = arch(nh, return_sequences=True, stateful=True)\n",
    "h2layer = arch(nh, stateful=True)\n",
    "is_skip = True\n",
    "h1 = h1layer(inp)\n",
    "i2 = concatenate([inp, h1])\n",
    "h2 = h2layer(i2)\n",
    "h1last = Lambda(lambda h: h[:,-1,:])(h1)\n",
    "rnnout = concatenate([h1last, h2])\n",
    "beta_var = K.variable(1.0)\n",
    "d = Dense(len(chars))(rnnout)\n",
    "d = Lambda(lambda d: d * beta_var)(d)\n",
    "out = Activation('softmax')(d)\n",
    "m = Model([inp], [out])\n",
    "m.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "m.summary()\n",
    "\n",
    "# Load the weights\n",
    "m.load_weights(\"charmodel.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellName: Ex5-2 (#12)\n",
    "### CellType: Exercise\n",
    "### Cell instruction: Instructions for question 9-10\n",
    "\n",
    "## RNN: Sampling from a character model\n",
    "In the cell below a function is defined that perform the actual sampling. It takes three parameters as input. (i) the starting sequence *seed*, (ii) the length of the sequence to generate *seqLen* and (iii) the temperature used during sampling *temp*. \n",
    "\n",
    "#### Question 9\n",
    "Run the cell below with the given parameters. **Does it look like C++ code?**\n",
    "\n",
    "#### Question 10\n",
    "Change the seed to something else! **What happens when you decrease/increase the temperature (e.g 0.7-1.5)?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampletxt(seed=\" \", n=50, t=1.0):\n",
    "    m.reset_states()\n",
    "    K.set_value(beta_var, 1/t)\n",
    "\n",
    "    for c in seed:\n",
    "        x_pred = np.zeros((1, 1, len(chars)))\n",
    "        x_pred[0, 0, char_indices[c]] = 1.\n",
    "        p = m.predict(x_pred, verbose=[0])\n",
    "        \n",
    "    txt = []\n",
    "    for i in range(n):\n",
    "        preds = p[0].astype('float64')\n",
    "        preds = preds/np.sum(preds) # some numericol issue\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        next_index = np.argmax(probas)\n",
    "        txt.append(chars[next_index])\n",
    "        p = m.predict(probas[None,:,:], verbose=0)\n",
    "\n",
    "    return ''.join(txt)\n",
    "\n",
    "#seed = \" \"\n",
    "#seed = \"void \"\n",
    "seed = \"for (int\"\n",
    "seqLen = 500\n",
    "temp = 1.0\n",
    "\n",
    "print(seed + sampletxt(seed,seqLen,temp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The report!\n",
    "\n",
    "\n",
    "### Name\n",
    "\n",
    "### Introduction\n",
    "\n",
    "### Answers to questions\n",
    "\n",
    "### Summary\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
